defaults:
  - common
  - ../modules/data/offline_datamodule@data
  - meta_solver: poisson1d_meta_solver_default
  - solver: pytorch_jacobi_default
  - surrogate: poisson1d_surrogate_default


meta_solver:
  params_learn: 
    x0: 
      - ${dim}
  features:
    b: 
      - ${dim}
  model:
    num_layers: 2
    num_neurons: 512
  
solver:
  _target_: nigbms.modules.solvers.PyTorchJacobi
  params_fix: 
    omega: 1.0
    history_length: 100
  params_learn: 
    x0: 
      - ${dim}
      - 1

surrogate:
  params_fix: ${solver.params_fix}
  params_learn: ${solver.params_learn}
  features: 
    b: 
      - ${dim}
    x0: 
      - ${dim}
    # xn: 
    #   - ${dim}
    # xn_sin-x0_sin:
    #   - ${dim}
    # xn-x0:
    #   - ${dim}
    # x: 
    #   - ${dim}
  model:
    out_dim: ${solver.params_fix.history_length}
    num_layers: 0
    num_neurons: 1024
    init_weight: 
      dist: uniform
      scale: 1.0e-3

constructor:
  _target_: nigbms.modules.constructors.ThetaConstructor
  _recursive_: False
  params: 
    x0:
      encdec: 
        _target_: nigbms.modules.constructors.SinEncDec
        enc_dim: ${dim}
        dec_dim: ${dim}
      shape: ${solver.params_learn.x0}
    

wrapper:
  opt:
    _target_: torch.optim.Adam
    lr: 1.0e-3
    # momentum: 0.9
  loss:
    _target_: nigbms.modules.losses.SurrogateSolverLoss
    weights:
      y_loss: 0
      # dvf_loss: 1
      dvL_loss: 1
    reduce: True
  clip: 10.0
  cfg:
    grad_type: cv_fwd
    jvp_type: forwardAD
    eps: 1.0e-10
    Nv: 1
    v_scale: 1.0
    v_dist: rademacher
  
loss:
  _target_: nigbms.modules.losses.MetaSolverLoss
  weights:
    iter_r_proxy: 1
    # r0: 1
  reduce: True
  
opt:
  _target_: torch.optim.Adam
  lr: 0 # 1.0e-4
sch:
  _target_: torch.optim.lr_scheduler.MultiStepLR
  milestones: [100]
  gamma: 0.1
  
callbacks:
  - _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: ${monitor}
    patience: 10
    mode: min
    verbose: True
  - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: epoch
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    monitor: ${monitor}
    mode: min
    save_top_k: 0
    save_last: False

trainer:
  max_epochs: 20
  accelerator: gpu
  devices: 1
  check_val_every_n_epoch: 20
  log_every_n_steps: 1
  fast_dev_run: False

seed: 0
monitor: val/iter_r
dtype: torch.float64
test: False
dim: 31
compile: False
logging: True
warmup: 0