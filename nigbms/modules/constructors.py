import numpy as np
import torch
from tensordict import TensorDict
from torch import Tensor
from torch.nn import Module


class ThetaConstructor(Module):
    """Construct theta from the encoded theta.
    This is necessary for two reasons:
    1.  Theta generated by the meta-solver is a single tensor, but solver takes a dictionary of parameters.
        Thus, we need to split the tensor into multiple solver parameters (e.g. initial guess + preconditioner).
    2.  Theta generated by the meta-solver may be encoded in a lower-dimensional space,
        and we need to decode it to the original space.
        This is important becasue the variance of CVFG is lower in the lower-dimensional space.

    """

    def __init__(self, params) -> None:
        super().__init__()
        self.params = params

    def forward(self, theta: Tensor) -> TensorDict:
        theta_dict = TensorDict({})
        idx = 0
        for k, v in self.params.items():
            assert v.codec.param_dim == np.prod(v.shape)
            param = v.codec.decode(theta[:, idx : idx + v.codec.latent_dim])
            theta_dict[k] = param.reshape(-1, *v.shape)
            idx += v.codec.latent_dim
        # theta_dict["enc"] = theta.unsqueeze(-1)
        return theta_dict


class Codec(Module):
    def __init__(self, param_dim: int, latent_dim: int) -> None:
        """Initialize the codec.

        Args:
            param_dim (int): solver parameter dimension
            latent_dim (int): latent dimension
        """
        super().__init__()
        assert param_dim >= latent_dim
        self.param_dim = param_dim
        self.latent_dim = latent_dim

    def forward(self, x: Tensor) -> Tensor:
        raise NotImplementedError

    def encode(self, x: Tensor) -> Tensor:
        raise NotImplementedError

    def decode(self, z: Tensor) -> Tensor:
        raise NotImplementedError


class IdentityCodec(Codec):
    def __init__(self, param_dim: int = 128, latent_dim: int = 128):
        assert param_dim == latent_dim
        super().__init__(param_dim, latent_dim)

    def encode(self, x: Tensor) -> Tensor:
        z = x
        return z

    def decode(self, z: Tensor) -> Tensor:
        x = z
        return x


class SinCodec(Codec):
    def __init__(self, param_dim: int = 128, latent_dim: int = 128):
        super().__init__(param_dim, latent_dim)
        frequencies = torch.arange(1, latent_dim + 1).unsqueeze(-1)  # (latent_dim, 1)
        phases = (torch.tensor([i / (param_dim + 1) for i in range(1, param_dim + 1)]) * torch.pi).unsqueeze(
            0
        )  # (1, param_dim)
        self.basis = torch.sin(frequencies * phases)  # (latent_dim, param_dim)
        self.basis = self.basis.unsqueeze(0)  # (1, latent_dim, param_dim) to broadcast for batch

    def encode(self, x: Tensor) -> Tensor:
        x = x.reshape(-1, self.param_dim, 1)
        z = torch.matmul(self.basis, x).squeeze(-1)
        return z

    def decode(self, z: Tensor) -> Tensor:
        z = z.reshape(-1, self.latent_dim, 1)
        x = torch.matmul(self.basis.transpose(1, 2), z).squeeze(-1)
        return x


# class SinDecoder(Codec):
#     def __init__(self, enc_dim: int = 128, dec_dim: int = 128):
#         super().__init__(enc_dim, dec_dim)
#         self.basis = torch.sin(
#             torch.arange(1, dec_dim + 1).unsqueeze(-1)
#             * torch.tensor([i / (dec_dim + 1) for i in range(1, dec_dim + 1)])
#             * torch.pi
#         )
#         self.basis = self.basis.unsqueeze(0)  # (1, out_dim, n_basis)
#         self.basis = self.basis.cuda()

#     def forward(self, theta: Tensor) -> Tensor:
#         decoded_theta = torch.matmul(self.basis, theta.unsqueeze(-1))  # (bs, out_dim, 1)
#         return decoded_theta.squeeze()


# class SinEncoder(Codec):
#     def __init__(self, enc_dim: int = 128, dec_dim: int = 128):
#         super().__init__(enc_dim, dec_dim)
#         self.basis = torch.sin(
#             torch.arange(1, dec_dim + 1).unsqueeze(-1)
#             * torch.tensor([i / (dec_dim + 1) for i in range(1, dec_dim + 1)])
#             * torch.pi
#         )
#         self.basis = self.basis.unsqueeze(0)  # (1, out_dim, n_basis)
#         self.basis = self.basis.cuda()

#     def forward(self, signal: Tensor) -> Tensor:
#         freq_signal = torch.matmul(self.basis.transpose(1, 2), signal.reshape(-1, self.dec_dim, 1))

#         return freq_signal.squeeze()


# class InterpolateDecoder(Module):
#     def __init__(self, out_dim: int = 32, mode="linear"):
#         super().__init__()
#         self.out_dim = out_dim
#         self.mode = mode

#     def forward(self, x: Tensor) -> Tensor:
#         x = x.unsqueeze(1)
#         scale_factor = self.out_dim // x.shape[-1]
#         interpolated_signal = F.interpolate(x, scale_factor=scale_factor, mode=self.mode, align_corners=True)

#         return interpolated_signal.squeeze(1)


# class InterpolateDecoder2D(Module):
#     def __init__(self, out_dim: int = 32, mode="bilinear"):
#         super().__init__()
#         self.out_dim = out_dim
#         self.mode = mode

#     def forward(self, signal: Tensor) -> Tensor:
#         bs, n2 = signal.shape
#         n = int(n2**0.5)
#         signal = signal.reshape(bs, 1, n, n)
#         scale_factor = self.out_dim // n
#         interpolated_signal = F.interpolate(signal, scale_factor=scale_factor, mode=self.mode, align_corners=True)

#         return interpolated_signal.reshape(bs, -1)


# class FFTEncoder(Module):
#     def __init__(self, out_dim: int = 32):
#         super().__init__()
#         self.out_dim = out_dim

#     def forward(self, signal: Tensor) -> Tensor:
#         freq_signal = torch.fft.rfft(signal, dim=-1)[..., : self.out_dim // 2]
#         freq_signal = torch.view_as_real(freq_signal).reshape(-1, self.out_dim)
#         return freq_signal


# class IFFTDecoder(Module):
#     def __init__(self, out_dim: int = 128):
#         super().__init__()
#         self.out_dim = out_dim

#     def forward(self, freq_signal: Tensor) -> Tensor:
#         n_components = freq_signal.shape[-1] // 2
#         freq_signal = torch.view_as_complex(freq_signal.reshape(-1, n_components, 2))
#         signal = torch.fft.irfft(freq_signal, n=self.out_dim, dim=-1)
#         return signal


# # %%
