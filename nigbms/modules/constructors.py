import numpy as np
import torch
from tensordict import TensorDict
from torch import Tensor
from torch.nn import Module, ModuleList, Parameter
from torch.nn.functional import interpolate


class ThetaConstructor(Module):
    """Construct theta from the encoded theta.
    This is necessary for two reasons:
    1.  Theta generated by the meta-solver is a single tensor, but solver takes a dictionary of parameters.
        Thus, we need to split the tensor into multiple solver parameters (e.g. initial guess + preconditioner).
    2.  Theta generated by the meta-solver may be encoded in a lower-dimensional space,
        and we need to decode it to the original space.
        This is important becasue the variance of CVFG is lower in the lower-dimensional space.

    """

    def __init__(self, params) -> None:
        super().__init__()
        self.params = params
        self.codecs = ModuleList([v.codec for v in params.values()])  # register codecs as submodules to move to cuda

    def forward(self, theta: Tensor) -> TensorDict:
        theta_dict = TensorDict({}, batch_size=theta.shape[0], device=theta.device)
        idx = 0
        for k, v in self.params.items():
            assert v.codec.param_dim == np.prod(v.shape)
            param = v.codec.decode(theta[:, idx : idx + v.codec.latent_dim])
            theta_dict[k] = param.reshape(-1, *v.shape)
            idx += v.codec.latent_dim

        return theta_dict


class Codec(Module):
    def __init__(self, param_dim: int, latent_dim: int) -> None:
        """Initialize the codec.

        Args:
            param_dim (int): solver parameter dimension
            latent_dim (int): latent dimension
        """
        super().__init__()
        assert param_dim >= latent_dim
        self.param_dim = param_dim
        self.latent_dim = latent_dim

    def forward(self, x: Tensor) -> Tensor:
        raise NotImplementedError

    def encode(self, x: Tensor) -> Tensor:
        raise NotImplementedError

    def decode(self, z: Tensor) -> Tensor:
        raise NotImplementedError


class IdentityCodec(Codec):
    def __init__(self, param_dim: int = 128, latent_dim: int = 128):
        assert param_dim == latent_dim
        super().__init__(param_dim, latent_dim)

    def encode(self, x: Tensor) -> Tensor:
        z = x
        return z

    def decode(self, z: Tensor) -> Tensor:
        x = z
        return x


class SinCodec(Codec):
    def __init__(self, param_dim: int = 128, latent_dim: int = 128):
        super().__init__(param_dim, latent_dim)
        frequencies = torch.arange(1, latent_dim + 1).unsqueeze(-1)  # (latent_dim, 1)
        phases = (torch.tensor([i / (param_dim + 1) for i in range(1, param_dim + 1)]) * torch.pi).unsqueeze(
            0
        )  # (1, param_dim)
        self.basis = torch.sin(frequencies * phases)  # (latent_dim, param_dim)
        self.basis = self.basis.unsqueeze(0)  # (1, latent_dim, param_dim) to broadcast for batch
        self.basis = self.basis / self.basis.norm(dim=-1, keepdim=True)  # normalize basis
        self.basis = Parameter(self.basis, requires_grad=False)  # set as fixed parameter to move to cuda

    def encode(self, x: Tensor) -> Tensor:
        x = x.reshape(-1, self.param_dim, 1)
        z = torch.matmul(self.basis, x).squeeze(-1)
        return z

    def decode(self, z: Tensor) -> Tensor:
        z = z.reshape(-1, self.latent_dim, 1)
        x = torch.matmul(self.basis.transpose(1, 2), z).squeeze(-1)
        return x


class LinearCodec(Codec):
    def __init__(self, param_dim: int = 128, latent_dim: int = 128):
        super().__init__(param_dim, latent_dim)

    def encode(self, x: Tensor) -> Tensor:
        z = interpolate(x.reshape(-1, 1, self.param_dim), size=self.latent_dim)
        return z.squeeze(1)

    def decode(self, z: Tensor) -> Tensor:
        x = interpolate(z.reshape(-1, 1, self.latent_dim), size=self.param_dim)
        return x.squeeze(1)


# class FFTEncoder(Module):
#     def __init__(self, out_dim: int = 32):
#         super().__init__()
#         self.out_dim = out_dim

#     def forward(self, signal: Tensor) -> Tensor:
#         freq_signal = torch.fft.rfft(signal, dim=-1)[..., : self.out_dim // 2]
#         freq_signal = torch.view_as_real(freq_signal).reshape(-1, self.out_dim)
#         return freq_signal


# class IFFTDecoder(Module):
#     def __init__(self, out_dim: int = 128):
#         super().__init__()
#         self.out_dim = out_dim

#     def forward(self, freq_signal: Tensor) -> Tensor:
#         n_components = freq_signal.shape[-1] // 2
#         freq_signal = torch.view_as_complex(freq_signal.reshape(-1, n_components, 2))
#         signal = torch.fft.irfft(freq_signal, n=self.out_dim, dim=-1)
#         return signal


# # %%
